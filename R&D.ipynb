{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Node' from 'langgraph' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Graph\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node, LLMNode\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Node' from 'langgraph' (unknown location)"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langgraph.graph import Graph\n",
    "from langgraph import Node, LLMNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API Key: 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\n"
     ]
    }
   ],
   "source": [
    "# Load the variables from the .env file into the environment\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API keys using os.getenv\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Optionally, check that the keys are loaded properly\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY not found. Please add it to your .env file.\")\n",
    "\n",
    "# Print (or use) the API keys as needed\n",
    "print(\"Groq API Key:\", groq_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM(prompt: str) -> str:\n",
    "    \"\"\"Generate a completion using the Groq API.\"\"\"\n",
    "    \n",
    "    completion = groq_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = LLM(\"What is the capital of France?\")\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Copy of OpenSecrets.org _ FTX_Alameda Research Contributions - Direct Contributions & JFC Distributions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cycle                     int64\n",
       "State/Federal            object\n",
       "contribid                object\n",
       "contrib                  object\n",
       "City                     object\n",
       "State                    object\n",
       "Zip                      object\n",
       "Fecoccemp                object\n",
       "orgname                  object\n",
       "ultorg                   object\n",
       "date             datetime64[ns]\n",
       "amount                   object\n",
       "recipid                  object\n",
       "recipient                object\n",
       "party                    object\n",
       "recipcode                object\n",
       "type                     object\n",
       "fectransid               object\n",
       "pg                       object\n",
       "cmteid                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "val2 = df.dtypes\n",
    "val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cycle', 'State/Federal', 'contribid', 'contrib', 'City', 'State',\n",
       "       'Zip', 'Fecoccemp', 'orgname', 'ultorg', 'date', 'amount', 'recipid',\n",
       "       'recipient', 'party', 'recipcode', 'type', 'fectransid', 'pg',\n",
       "       'cmteid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = df.columns\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Schema from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided data, here is a schema for the table:\n",
      "\n",
      "Table Name: Contributions\n",
      "Columns:\n",
      "- cycle: INTEGER\n",
      "- State_Federal: TEXT\n",
      "- contribid: TEXT\n",
      "- contrib: TEXT\n",
      "- City: TEXT\n",
      "- State: TEXT\n",
      "- Zip: TEXT\n",
      "- Fecoccemp: TEXT\n",
      "- orgname: TEXT\n",
      "- ultorg: TEXT\n",
      "- date: DATE\n",
      "- amount: DECIMAL(10, 2)\n",
      "- recipid: TEXT\n",
      "- recipient: TEXT\n",
      "- party: TEXT\n",
      "- recipcode: TEXT\n",
      "- type: TEXT\n",
      "- fectransid: TEXT\n",
      "- pg: TEXT\n",
      "- cmteid: TEXT\n",
      "\n",
      "Note:\n",
      "- I've used DECIMAL\n"
     ]
    }
   ],
   "source": [
    "sample_schema = \"\"\"\n",
    "Table Name: employees\n",
    "Columns:\n",
    "- id: INTEGER\n",
    "- name: TEXT\n",
    "- salary: FLOAT\n",
    "- department: TEXT\n",
    "\"\"\"\n",
    "prompt = f\"Based on the data, the columns are {val}. The datatypes are {val2} Create a schema for the data. It should look like {sample_schema}\"\n",
    "schema = LLM(prompt)\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your file is not named \"langgraph.py\" to avoid shadowing the package.\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# This function represents your node that uses an LLM to convert a natural language query into SQL.\n",
    "def generate_sql_node(state):\n",
    "    # The state already contains a \"schema\" field that is baked in.\n",
    "    query = state[\"query\"]\n",
    "    schema = state[\"schema\"]\n",
    "    prompt = (\n",
    "        \"You are a SQL expert. Given the following table schema:\\n\"\n",
    "        f\"{schema}\\n\"\n",
    "        \"Convert the natural language query into a SQL query:\\n\"\n",
    "        f\"{query}\"\n",
    "    )\n",
    "    # Initialize your LLM (adjust the parameters as needed).\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    response = llm(prompt)\n",
    "    # Return the generated SQL as part of the updated state.\n",
    "    return {\"sql\": response}\n",
    "\n",
    "# Prepare an initial state containing your query and your table schema.\n",
    "initial_state = {\n",
    "    \"query\": \"Show me all active users.\",\n",
    "    \"schema\": \"users(id INTEGER, name TEXT, status TEXT)\"\n",
    "}\n",
    "\n",
    "# Build the graph using StateGraph (this is the public API in LangGraph).\n",
    "graph_builder = StateGraph(dict)\n",
    "graph_builder.add_node(\"generate_sql\", generate_sql_node)\n",
    "graph_builder.add_edge(START, \"generate_sql\")\n",
    "graph_builder.add_edge(\"generate_sql\", END)\n",
    "\n",
    "# Compile the graph (using an in-memory checkpointer for persistence).\n",
    "graph = graph_builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Invoke the graph with the initial state.\n",
    "result = graph.invoke(initial_state)\n",
    "print(\"Generated SQL query:\")\n",
    "print(result[\"sql\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your file is not named \"langgraph.py\" to avoid shadowing the package.\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "# This node uses your custom LLM to convert a natural language query into a SQL query.\n",
    "def generate_sql_node(state):\n",
    "    # The state already contains a \"schema\" field that is baked in.\n",
    "    query = state[\"query\"]\n",
    "    schema = state[\"schema\"]\n",
    "    prompt = (\n",
    "        \"You are a SQL expert. Given the following table schema:\\n\"\n",
    "        f\"{schema}\\n\"\n",
    "        \"Convert the natural language query into a SQL query:\\n\"\n",
    "        f\"{query}\"\n",
    "    )\n",
    "    # Use your custom LLM function to generate the SQL query.\n",
    "    response = LLM(prompt)\n",
    "    # Return the generated SQL as part of the updated state.\n",
    "    return {\"sql\": response}\n",
    "\n",
    "# Prepare an initial state containing your query and your table schema.\n",
    "initial_state = {\n",
    "    \"query\": \"Show me all active users.\",\n",
    "    \"schema\": \"users(id INTEGER, name TEXT, status TEXT)\"\n",
    "}\n",
    "\n",
    "# Build the graph using the public StateGraph API.\n",
    "graph_builder = StateGraph(dict)\n",
    "graph_builder.add_node(\"generate_sql\", generate_sql_node)\n",
    "graph_builder.add_edge(START, \"generate_sql\")\n",
    "graph_builder.add_edge(\"generate_sql\", END)\n",
    "\n",
    "# Compile the graph using an in-memory checkpointer for persistence.\n",
    "graph = graph_builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Invoke the graph with the initial state.\n",
    "result = graph.invoke(initial_state)\n",
    "print(\"Generated SQL query:\")\n",
    "print(result[\"sql\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"deepeval_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>generated_sql</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find total contributions by each contributor.</td>\n",
       "      <td>SELECT \\r\\n    contribid,\\r\\n    contrib,\\r\\n ...</td>\n",
       "      <td>```sql\\nSELECT contrib, SUM(amount) AS total_c...</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List all contributions made in the year 2022.</td>\n",
       "      <td>SELECT \\r\\n    contrib,\\r\\n    recipient,\\r\\n ...</td>\n",
       "      <td>```sql\\nSELECT * \\nFROM campaign_contributions...</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find the top 5 recipients who received the hig...</td>\n",
       "      <td>SELECT \\r\\n    recipid,\\r\\n    recipient,\\r\\n ...</td>\n",
       "      <td>```sql\\nSELECT recipient, SUM(amount) as total...</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Count the number of contributions made by cont...</td>\n",
       "      <td>SELECT \\r\\n    COUNT(*) as total_contributions...</td>\n",
       "      <td>```sql\\nSELECT COUNT(*) \\nFROM campaign_contri...</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find the average contribution amount.</td>\n",
       "      <td>SELECT \\r\\n    ROUND(AVG(amount), 2) as averag...</td>\n",
       "      <td>```sql\\nSELECT AVG(amount) FROM campaign_contr...</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0      Find total contributions by each contributor.   \n",
       "1      List all contributions made in the year 2022.   \n",
       "2  Find the top 5 recipients who received the hig...   \n",
       "3  Count the number of contributions made by cont...   \n",
       "4              Find the average contribution amount.   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  SELECT \\r\\n    contribid,\\r\\n    contrib,\\r\\n ...   \n",
       "1  SELECT \\r\\n    contrib,\\r\\n    recipient,\\r\\n ...   \n",
       "2  SELECT \\r\\n    recipid,\\r\\n    recipient,\\r\\n ...   \n",
       "3  SELECT \\r\\n    COUNT(*) as total_contributions...   \n",
       "4  SELECT \\r\\n    ROUND(AVG(amount), 2) as averag...   \n",
       "\n",
       "                                       generated_sql result  \n",
       "0  ```sql\\nSELECT contrib, SUM(amount) AS total_c...   PASS  \n",
       "1  ```sql\\nSELECT * \\nFROM campaign_contributions...   PASS  \n",
       "2  ```sql\\nSELECT recipient, SUM(amount) as total...   PASS  \n",
       "3  ```sql\\nSELECT COUNT(*) \\nFROM campaign_contri...   PASS  \n",
       "4  ```sql\\nSELECT AVG(amount) FROM campaign_contr...   PASS  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
